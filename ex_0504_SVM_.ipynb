{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ex_0504 - SVM - .ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Exercise #0504"
      ],
      "metadata": {
        "id": "JZLotp_s70k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Classification with SVM:"
      ],
      "metadata": {
        "id": "ZTBxLv1t70lB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import warnings\r\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "warnings.filterwarnings(action='ignore')                  # Turn off the warnings.\r\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "I-Otfmvf70lD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1. Read in data:"
      ],
      "metadata": {
        "id": "x93aNXfB70lF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Load data.\r\n",
        "data = load_iris()"
      ],
      "outputs": [],
      "metadata": {
        "id": "m7x5nnaY70lG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Explanatory variables.\r\n",
        "X = data['data']\r\n",
        "columns = list(data['feature_names'])\r\n",
        "print(columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ]
        }
      ],
      "metadata": {
        "id": "zDahH2Vt70lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8570d6-ba4b-4ba0-ed97-8cb5eb8ccf1e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Response variable.\r\n",
        "Y = data['target']\r\n",
        "labels = list(data['target_names'])\r\n",
        "print(labels)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa', 'versicolor', 'virginica']\n"
          ]
        }
      ],
      "metadata": {
        "id": "K8L9FRBS70lI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5139a3a5-c2bd-40a5-dc28-1203dd8db1a3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aG_jKj7j70lK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVMs) are a method that uses points in a transformed problem space that best separate classes into two groups. Classification for multiple classes is supported by a one-vs-all method. SVM also supports regression by modeling the function with a minimum amount of allowable error.\r\n",
        "\r\n",
        "Question 1 : Use SVC() to fit a support vector machine to iris data.\r\n"
      ],
      "metadata": {
        "id": "Tp_RmlQ8oXYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "\r\n",
        "#Create a svm Classifier\r\n",
        "\r\n",
        "model = SVC(kernel='linear') # Linear Kernel\r\n",
        "\r\n",
        "#Train the model using the training sets\r\n",
        "\r\n",
        "model.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# make predictions\r\n",
        "\r\n",
        "predicted = model.predict(X_test)\r\n",
        "expected = Y_test\r\n",
        "print(model)\r\n",
        "\r\n",
        "# summarize the fit of the model\r\n",
        "\r\n",
        "print('classification report : \\n',metrics.classification_report(expected, predicted))\r\n",
        "print('Confusion matrix : \\n',metrics.confusion_matrix(expected, predicted))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC(kernel='linear')\n",
            "classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "Confusion matrix : \n",
            " [[16  0  0]\n",
            " [ 0 17  0]\n",
            " [ 0  0 12]]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBPXSjfxpV9y",
        "outputId": "e9e23044-0479-42b2-9ed8-63f553b21359"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. SVM hyperparameter optimization (RBF kernel):\n",
        "\n",
        "The SVM algorithm is implemented in practice using a kernel.\n",
        "\n",
        "The learning of the hyperplane in linear SVM is done by transforming the problem using some linear algebra, which is out of the scope of this introduction to SVM.\n",
        "\n",
        "https://towardsdatascience.com/a-to-z-of-svm-machine-learning-for-everyone-902fdd8fe9a1\n",
        "\n",
        "\n",
        "\n",
        "## Tuning Hyperparameters\n",
        "\n",
        "\n",
        "- Kernel, The main function of the kernel is to transform the given dataset input data into the required form. There are various types of functions such as linear, polynomial, and radial basis function (RBF). Polynomial and RBF are useful for non-linear hyperplane. Polynomial and RBF kernels compute the separation line in the higher dimension. In some of the applications, it is suggested to use a more complex kernel to separate the classes that are curved or nonlinear. \n",
        "\n",
        "- Gamma; A lower value of Gamma will loosely fit the training dataset, whereas a higher value of gamma will exactly fit the training dataset, which causes over-fitting. In other words, you can say a low value of gamma considers only nearby points in calculating the separation line, while the a value of gamma considers all the data points in the calculation of the separation line.\n"
      ],
      "metadata": {
        "id": "vshQO-xX70lL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's do some tuning !!! :) "
      ],
      "metadata": {
        "id": "gACYfgRkwoZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\r\n",
        "Question \r\n",
        "\r\n",
        "- \r\n",
        "There are two parameters for an RBF kernel SVM namely C and gamma, \r\n",
        "Read the documentation and use gridCV to find best gama and best C.\r\n",
        "\r\n",
        "\r\n",
        "https://aneesha.medium.com/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0"
      ],
      "metadata": {
        "id": "ZD8MezZ-xJH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C     : Penalty parameter. <br>\n",
        "gamma : kernel parameter ($\\gamma$)."
      ],
      "metadata": {
        "id": "9lNLLQ9i70lN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "C_grid = 0.02*np.arange(1,20)\r\n",
        "gamma_grid = 0.02*np.arange(1,50)\r\n",
        "parameters = {'C': C_grid, 'gamma' : gamma_grid}\r\n",
        "#your code goes here\r\n",
        "gridCV =  GridSearchCV(svm.SVC(kernel='rbf'), parameters, cv=10, n_jobs = -1)\r\n",
        "gridCV.fit(X_train, Y_train)\r\n",
        "best_C = gridCV.best_params_['C']\r\n",
        "best_gamma = gridCV.best_params_['gamma']"
      ],
      "outputs": [],
      "metadata": {
        "id": "zv6ppH_370lO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "print(\"SVM best C : \" + str(best_C))\r\n",
        "print(\"SVM best gamma : \" + str(best_gamma))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best C : 0.2\n",
            "SVM best gamma : 0.78\n"
          ]
        }
      ],
      "metadata": {
        "id": "o9JYJVCU70lP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3600e2-42fc-48ec-9a2b-4677e7310063"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use best C and best gamma as parameters to our SVM model"
      ],
      "metadata": {
        "id": "EY1ifhNWySok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "SVM_best =SVC(kernel='rbf', gamma=0.96, C=0.16) #your code goes here\r\n",
        "SVM_best.fit(X_train, Y_train)\r\n",
        "Y_pred = SVM_best.predict(X_test)\r\n",
        "print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best accuracy : 0.978\n"
          ]
        }
      ],
      "metadata": {
        "id": "5CRkH0zI70lQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76ed7e0-23c3-4940-bfa8-05020a47075a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "\n",
        "- Set C = 0.8 and gama to 0.2 and check the accuracy of your SVM and check the accuracy of your model.\n",
        "- Set C = 0.02 and gama to 0.2 and check the accuracy of your SVM.\n",
        "\n",
        "What will happen if C is to small or to big?"
      ],
      "metadata": {
        "id": "dHsqgFOUJ7Yx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "SVM_best =SVC(kernel='rbf', gamma=0.2, C=0.8) #your code goes here\r\n",
        "SVM_best.fit(X_train, Y_train)\r\n",
        "Y_pred = SVM_best.predict(X_test)\r\n",
        "print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best accuracy : 1.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "HvCLe_ykLYmu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "SVM_best =SVC(kernel='rbf', gamma=0.2, C=0.02) #your code goes here\r\n",
        "SVM_best.fit(X_train, Y_train)\r\n",
        "Y_pred = SVM_best.predict(X_test)\r\n",
        "print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best accuracy : 0.622\n"
          ]
        }
      ],
      "metadata": {
        "id": "p6OH6l8rLYaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The C value controls the penalty of misclassification. A large value of C would result in a higher penalty for misclassification and a smaller value of C will result in a smaller penalty of misclassification. With a larger value of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. \r\n",
        "So we notice that as the value of C increases, the model accuracy increases. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3. SVM hyperparameter optimization (Polynomial kernel):\n",
        "Now let's do the same steps but with the polynomial kernel,  use gridCV to find best gama and best C in a polynomial kernel."
      ],
      "metadata": {
        "id": "aFC_5bD170lQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "#Your code goes here\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "\r\n",
        "C_grid = 0.02*np.arange(1,20)\r\n",
        "gamma_grid = 0.02*np.arange(1,50)\r\n",
        "parameters = {'C': C_grid, 'gamma' : gamma_grid}\r\n",
        "gridCV =  GridSearchCV(svm.SVC(kernel='poly'), parameters, cv=None, n_jobs = -1)\r\n",
        "gridCV.fit(X_train, Y_train)\r\n",
        "best_C = gridCV.best_params_['C']\r\n",
        "best_gamma = gridCV.best_params_['gamma']"
      ],
      "outputs": [],
      "metadata": {
        "id": "IcX4TUWN70lS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "print(\"SVM best C : \" + str(best_C))\r\n",
        "print(\"SVM best gamma : \" + str(best_gamma))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best C : 0.04\n",
            "SVM best gamma : 0.06\n"
          ]
        }
      ],
      "metadata": {
        "id": "2rUKMEaf70lT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "SVM_best = SVC(kernel='poly', C=best_C,gamma=best_gamma)\r\n",
        "SVM_best.fit(X_train, Y_train)\r\n",
        "Y_pred = SVM_best.predict(X_test)\r\n",
        "print( \"SVM best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM best accuracy : 0.956\n"
          ]
        }
      ],
      "metadata": {
        "id": "zXJ6BsOI70lU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "mY9XHe5u70lU"
      }
    }
  ]
}